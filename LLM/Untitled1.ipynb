{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd43774e-3bab-4495-9332-91ffc740c4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpradjinata/Documents/Research/OpenAIGym/venv/lib/python3.11/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.warn(\n",
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make('Pong-v0',render_mode='rgb_array')\n",
    "observation = env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8dd321e-89e0-47ba-9b14-0b19d87bc4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpradjinata/Documents/Research/OpenAIGym/venv/lib/python3.11/site-packages/gym/utils/passive_env_checker.py:289: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# Render the game state\n",
    "frame = env.render()\n",
    "import cv2\n",
    "\n",
    "# Convert to grayscale and resize to a lower resolution\n",
    "gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "small_frame = cv2.resize(gray_frame, (84, 84))  # Resize to 84x84 for simplicity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59ab9fb-7864-44fa-94b6-431d9954eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten image for the LLM input (example)\n",
    "input_to_llm = small_frame.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "086d1528-9b89-42d7-b339-ec2121c2df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"Ball is at (50, 30), player paddle is at y = 40, opponent paddle is at y = 60.\"\n",
    "# action_text = predict_action_llm(description)\n",
    "# print(f\"LLM suggests action: {action_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd355b06-2139-474d-af08-d09bd2eb342c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b00f655c-6e0e-40ae-9010-165bac2354b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/kdb6f8j523s5fh4syx6bp5bh0000gn/T/ipykernel_3013/3070159875.py:8: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
      "/var/folders/kh/kdb6f8j523s5fh4syx6bp5bh0000gn/T/ipykernel_3013/3070159875.py:17: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
      "/var/folders/kh/kdb6f8j523s5fh4syx6bp5bh0000gn/T/ipykernel_3013/3070159875.py:19: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  print(f\"MPS available: {torch.has_mps}\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "# Load the GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Check if MPS is available and use it\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def predict_action_llm(description):\n",
    "    input_ids = tokenizer.encode(description, return_tensors='pt', truncation=True).to(device)  # No max_length here\n",
    "    output = model.generate(input_ids, max_new_tokens=30)  # Control the output length\n",
    "    action_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return action_text\n",
    "\n",
    "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "\n",
    "print(f\"MPS available: {torch.has_mps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "781ea16a-e014-4fd8-8912-e3fa30e2225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_game_state(frame):\n",
    "    # Extract features of the frame: ball position, player paddle position, etc.\n",
    "    # For this example, I'm using placeholder values for positions.\n",
    "    ball_x, ball_y = 50, 30\n",
    "    player_paddle_y = 40\n",
    "    opponent_paddle_y = 60\n",
    "    \n",
    "    # Return a text description of the game state\n",
    "    description = (f\"Ball is at ({ball_x}, {ball_y}), \"\n",
    "                   f\"player paddle is at y = {player_paddle_y}, \"\n",
    "                   f\"opponent paddle is at y = {opponent_paddle_y}.\")\n",
    "    return description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "346d5dcd-291d-419e-a71b-5ca1ab9e5def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_action(action_text):\n",
    "    if \"up\" in action_text.lower():\n",
    "        return 2  # Move paddle up\n",
    "    elif \"down\" in action_text.lower():\n",
    "        return 3  # Move paddle down\n",
    "    else:\n",
    "        return 0  # Stay still\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b5a6285-79b6-48e1-b1e5-3dec9233ab50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Example: Call LLM decision every few frames, instead of every frame\n",
    "step = 0\n",
    "while True:\n",
    "    step += 1\n",
    "    frame = env.render()\n",
    "    \n",
    "    if step % 10 == 0:  # Call LLM only every 10 frames\n",
    "        description = describe_game_state(frame)\n",
    "        action_text = predict_action_llm(description)\n",
    "        action = map_action(action_text)\n",
    "    else:\n",
    "        action = 0  # Default action when not calling the LLM\n",
    "    \n",
    "    observation, reward, done, info, truncation = env.step(action)\n",
    "    print(reward)\n",
    "\n",
    "\n",
    "    \n",
    "    if done:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a832ef-c955-4a01-a084-c152bb29ab36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383c6db-62f6-47cc-84de-d5850c940345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
